"use client";

import React, { useState, useEffect, useCallback } from "react";
import Image from "next/image";
import { useRouter } from "next/navigation";
import { vapi } from "@/lib/actions/vapi.sdk";
import { interviewer } from "@/constants";
import { motion } from "framer-motion";

enum CallStatus {
Â  INACTIVE = "INACTIVE",
Â  CONNECTING = "CONNECTING",
Â  ACTIVE = "ACTIVE",
Â  FINISHED = "FINISHED",
}

interface SavedMessage {
Â  role: "user" | "system" | "assistant";
Â  content: string;
}

// Assuming AgentProps is defined elsewhere and includes userId, type, etc.
interface AgentProps {
Â  userName: string;
Â  userId: string;
Â  interviewId?: string;
Â  feedbackId?: string;
Â  type: "generate" | "fetch" | string;
Â  questions?: string[];
}

const Agent = ({
Â  userName,
Â  userId,
Â  type,
}: AgentProps) => {
Â  const router = useRouter();
Â  const [callStatus, setCallStatus] = useState<CallStatus>(CallStatus.INACTIVE);
Â  const [messages, setMessages] = useState<SavedMessage[]>([]);
Â  const [isSpeaking, setIsSpeaking] = useState(false);
Â  const [lastMessage, setLastMessage] = useState<string>("");
  
Â  // State to manage the questions and ID after generation
Â  const [interviewQuestions, setInterviewQuestions] = useState<string[]>([]);
Â  const [currentInterviewId, setCurrentInterviewId] = useState<string>(''); // Used to track if generation is complete

// --- Helper function for starting the interview call (Call 2) ---
Â  const handleInterviewStart = useCallback(async (questions: string[], interviewId: string) => {
  const Interviewer_assistant_id = process.env.NEXT_PUBLIC_VAPI_INTERVIEWER_ASSISTANT_ID!;
Â  Â  try {
Â  Â  Â  const formattedQuestions = questions.map((q: string) => `- ${q}`).join("\n");
Â  Â  Â  
Â  Â  Â  setCallStatus(CallStatus.CONNECTING);
Â  Â  Â  
Â  Â  Â  // Start the second call with the Interviewer Assistant
Â  Â  Â  await vapi.start(interviewer, {
Â  Â  Â  Â  variableValues: { 
Â  Â  Â  Â  Â  questions: formattedQuestions,
Â  Â  Â  Â  Â  interviewId: interviewId // Pass the ID to the Vapi Assistant
Â  Â  Â  Â  }, 
Â  Â  Â  });
Â  Â  Â  console.log(`Starting Interview Call for ID: ${interviewId}`);

Â  Â  } catch (error) {
Â  Â  Â  console.error("Error starting interview call:", error);
Â  Â  Â  setCallStatus(CallStatus.INACTIVE);
Â  Â  Â  alert("Failed to start the interview. Please try again.");
Â  Â  }
Â  }, [interviewer]);


// --- useEffect for Vapi Event Listeners ---
Â  useEffect(() => {
  console.log("interview id",currentInterviewId)
Â  Â  const onCallStart = () => setCallStatus(CallStatus.ACTIVE);
Â  Â  const onMessage = (message: any) => {
Â  Â  Â  if (message.type === "transcript" && message.transcriptType === "final") {
Â  Â  Â  Â  const newMessage = { role: message.role, content: message.transcript };
Â  Â  Â  Â  setMessages((prev) => [...prev, newMessage]);
Â  Â  Â  }
Â  Â  };
Â  Â  const onSpeechStart = () => setIsSpeaking(true);
Â  Â  const onSpeechEnd = () => setIsSpeaking(false);
Â  Â  const onError = (error: Error) => console.error("Error:", error);


Â  Â  const onCallEnd = async () => {
Â  Â  Â  // Check if the GENERATE call just ended and we haven't started the interview yet
Â  Â  Â  if (type === "generate" && currentInterviewId === '') {
Â  Â  Â  Â  console.log("Generation call ended. Fetching results to start interview...");

Â  Â  Â  Â  // 1. Fetch the newly created questions and ID from your backend
Â  Â  Â  Â  const response = await fetch("/api/vapi/generate", {
Â  Â  Â  Â  Â  method: "POST",
Â  Â  Â  Â  Â  headers: { "Content-Type": "application/json" },
Â  Â  Â  Â  Â  // Use 'action: "fetch"' to get the latest saved interview record
Â  Â  Â  Â  Â  body: JSON.stringify({ userid: userId, action: "fetch" }), 
Â  Â  Â  Â  });

Â  Â  Â  Â  const data = await response.json();

Â  Â  Â  Â  if (data.questions && data.questions.length > 0 && data.interviewId) {
Â  Â  Â  Â  Â  // 2. Store the data in state
Â  Â  Â  Â  Â  setInterviewQuestions(data.questions);
Â  Â  Â  Â  Â  setCurrentInterviewId(data.interviewId);

Â  Â  Â  Â  Â  // 3. Immediately start the second Vapi call (The Interview)
Â  Â  Â  Â  Â  await handleInterviewStart(data.questions, data.interviewId);

Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  console.error("âŒ Failed to retrieve generated questions/ID.");
Â  Â  Â  Â  Â  setCallStatus(CallStatus.INACTIVE); 
Â  Â  Â  Â  }
Â  Â  Â  } else {
Â  Â  Â  Â  // Condition: The final interview call has ended, or it was a non-generate flow.
Â  Â  Â  Â  setCallStatus(CallStatus.FINISHED);
Â  Â  Â  }
Â  Â  };


Â  Â  vapi.on("call-start", onCallStart);
Â  Â  vapi.on("call-end", onCallEnd);
Â  Â  vapi.on("message", onMessage);
Â  Â  vapi.on("speech-start", onSpeechStart);
Â  Â  vapi.on("speech-end", onSpeechEnd);
Â  Â  vapi.on("error", onError);

Â  Â  return () => {
Â  Â  Â  vapi.off("call-start", onCallStart);
Â  Â  Â  vapi.off("call-end", onCallEnd);
Â  Â  Â  vapi.off("message", onMessage);
Â  Â  Â  vapi.off("speech-start", onSpeechStart);
Â  Â  Â  vapi.off("speech-end", onSpeechEnd);
Â  Â  Â  vapi.off("error", onError);
Â  Â  };
Â  }, [userId, type, currentInterviewId, handleInterviewStart]); // Added dependencies


// --- useEffect for Message/Status updates (Kept mostly as is) ---
Â  useEffect(() => {
Â  Â  if (messages.length > 0) setLastMessage(messages[messages.length - 1].content);

Â  Â  const handleGenerateFeedback = async (msgs: SavedMessage[]) => {
Â  Â  Â  console.log("Feedback messages:", msgs);
Â  Â  Â  // You would use currentInterviewId here to save the feedback linked to the interview
Â  Â  Â  if (currentInterviewId) {
Â  Â  Â  Â  console.log(`Ready to save feedback for ID: ${currentInterviewId}`);
Â  Â  Â  Â  // API call to save feedback using currentInterviewId
Â  Â  Â  }
Â  Â  };

Â  Â  if (callStatus === CallStatus.FINISHED) {
Â  Â  Â  // Only redirect after the interview (the second call) is finished.
Â  Â  Â  if (type === "generate" && currentInterviewId) {
Â  Â  Â  Â  handleGenerateFeedback(messages); // Get final feedback
Â  Â  Â  Â  router.push(`/feedback/${currentInterviewId}`); // Example redirect to feedback page
Â  Â  Â  } else if (type !== "generate") {
Â  Â  Â  Â  handleGenerateFeedback(messages);
Â  Â  Â  }
Â  Â  }
Â  }, [messages, callStatus, type, router, currentInterviewId]); // Added currentInterviewId

// --- handleCall Function (Initiates Call 1 or Call 2 directly) ---
Â  const handleCall = async () => {
Â  try {
Â  Â  setCallStatus(CallStatus.CONNECTING);

Â  Â  // ğŸ”¹ Case 1: Generate Mode (Start the GENERATOR Assistant)
Â  Â  // This assistant collects user input, calls your API, and ENDS the call.
Â  Â  if (type === "generate") {
Â  Â  Â  await vapi.start(process.env.NEXT_PUBLIC_VAPI_WORKFLOW_ID!, {
Â  Â  Â  Â  variableValues: { userid: userId },
Â  Â  Â  });
Â  Â  Â  console.log("Started generate flow for user:", userId);
Â  Â  Â  return;
Â  Â  }

Â  Â  // ğŸ”¹ Case 2: Interview Mode (Fetch existing questions and start interview directly)
Â  Â  // Fetch questions from your backend (which reads from Firestore)
Â  Â  const response = await fetch("/api/vapi/generate", {
Â  Â  Â  method: "POST",
Â  Â  Â  headers: { "Content-Type": "application/json" },
Â  Â  Â  body: JSON.stringify({ userid: userId, action: "fetch" }),
Â  Â  });

Â  Â  const data = await response.json();

Â  Â  if (!data.questions || data.questions.length === 0 || !data.interviewId) {
Â  Â  Â  alert("No questions found for this user.");
Â  Â  Â  setCallStatus(CallStatus.INACTIVE);
Â  Â  Â  return;
Â  Â  }
    
Â  Â  // Start the interview call directly
Â  Â  await handleInterviewStart(data.questions, data.interviewId);

Â  } catch (err) {
Â  Â  console.error("Error starting Vapi call:", err);
Â  Â  setCallStatus(CallStatus.INACTIVE);
Â  }
};
;

Â  const handleDisconnect = () => {
Â  Â  setCallStatus(CallStatus.FINISHED);
Â  Â  vapi.stop();
Â  };

Â  return (
Â  Â  // ... (JSX remains the same)
Â  Â  <div className="relative flex flex-col justify-center items-center min-h-screen overflow-hidden bg-gradient-to-br from-black via-slate-900 to-blue-950 text-white">
Â  Â  Â  {/* ... */}
Â  Â  Â  {/* Main Content - Centered */}
Â  Â  Â  <div className="flex flex-col justify-center items-center gap-5 w-full h-screen">
Â  Â  Â  Â  {/* AI & User Row */}
Â  Â  Â  Â  <div className="flex justify-center items-center gap-8">
Â  Â  Â  Â  Â  {/* AI Interviewer Card */}
Â  Â  Â  Â  Â  <motion.div
Â  Â  Â  Â  Â  Â  className="relative flex flex-col items-center justify-center bg-white/10 backdrop-blur-2xl border border-white/20 rounded-3xl p-5 w-[260px] h-[230px] text-center shadow-[0_0_40px_rgba(0,255,255,0.15)] hover:shadow-[0_0_60px_rgba(0,255,255,0.3)] transition-all duration-500"
Â  Â  Â  Â  Â  Â  initial={{ opacity: 0, y: 30 }}
Â  Â  Â  Â  Â  Â  animate={{ opacity: 1, y: 0 }}
Â  Â  Â  Â  Â  Â  transition={{ duration: 0.9 }}
Â  Â  Â  Â  Â  >
Â  Â  Â  Â  Â  Â  <Image
Â  Â  Â  Â  Â  Â  Â  src="/agent_logo.jpg"
Â  Â  Â  Â  Â  Â  Â  alt="AI Interviewer"
Â  Â  Â  Â  Â  Â  Â  width={80}
Â  Â  Â  Â  Â  Â  Â  height={80}
Â  Â  Â  Â  Â  Â  Â  className="rounded-full border-4 border-cyan-400/30 shadow-[0_0_30px_rgba(0,255,255,0.4)] object-cover"
Â  Â  Â  Â  Â  Â  />
Â  Â  Â  Â  Â  Â  {isSpeaking && (
Â  Â  Â  Â  Â  Â  Â  <motion.span
Â  Â  Â  Â  Â  Â  Â  Â  className="absolute top-8 left-1/2 -translate-x-1/2 h-[100px] w-[100px] rounded-full border-4 border-cyan-300 opacity-70 animate-ping"
Â  Â  Â  Â  Â  Â  Â  Â  initial={{ scale: 1 }}
Â  Â  Â  Â  Â  Â  Â  Â  animate={{ scale: [1, 1.3, 1], opacity: [0.8, 0.3, 0.8] }}
Â  Â  Â  Â  Â  Â  Â  Â  transition={{ repeat: Infinity, duration: 1.5 }}
Â  Â  Â  Â  Â  Â  Â  ></motion.span>
Â  Â  Â  Â  Â  Â  )}
Â  Â  Â  Â  Â  Â  <h3 className="mt-3 text-cyan-300 font-semibold uppercase tracking-widest text-sm">
Â  Â  Â  Â  Â  Â  Â  AI Interviewer
Â  Â  Â  Â  Â  Â  </h3>
Â  Â  Â  Â  Â  Â  <p className="text-gray-300 text-xs mt-1">
Â  Â  Â  Â  Â  Â  Â  {isSpeaking ? "Listening carefully..." : "Waiting for response..."}
Â  Â  Â  Â  Â  Â  </p>
Â  Â  Â  Â  Â  </motion.div>

Â  Â  Â  Â  Â  {/* User Card */}
Â  Â  Â  Â  Â  <motion.div
Â  Â  Â  Â  Â  Â  className="relative flex flex-col items-center justify-center bg-white/10 backdrop-blur-2xl border border-white/20 rounded-3xl p-5 w-[260px] h-[230px] text-center shadow-[0_0_40px_rgba(0,255,255,0.15)] hover:shadow-[0_0_60px_rgba(0,255,255,0.3)] transition-all duration-500"
Â  Â  Â  Â  Â  Â  initial={{ opacity: 0, y: 40 }}
Â  Â  Â  Â  Â  Â  animate={{ opacity: 1, y: 0 }}
Â  Â  Â  Â  Â  Â  transition={{ duration: 1, delay: 0.3 }}
Â  Â  Â  Â  Â  >
Â  Â  Â  Â  Â  Â  <Image
Â  Â  Â  Â  Â  Â  Â  src="/user_logo.jpg"
Â  Â  Â  Â  Â  Â  Â  alt="User Avatar"
Â  Â  Â  Â  Â  Â  Â  width={80}
Â  Â  Â  Â  Â  Â  Â  height={80}
Â  Â  Â  Â  Â  Â  Â  className="rounded-full border-4 border-blue-400/30 shadow-[0_0_25px_rgba(0,255,255,0.3)] object-cover"
Â  Â  Â  Â  Â  Â  />
Â  Â  Â  Â  Â  Â  <h3 className="mt-3 text-cyan-200 font-semibold uppercase tracking-widest text-sm">
Â  Â  Â  Â  Â  Â  Â  {userName || "You"}
Â  Â  Â  Â  Â  Â  </h3>
Â  Â  Â  Â  Â  Â  <p className="text-gray-300 text-xs mt-1">
Â  Â  Â  Â  Â  Â  Â  {callStatus === CallStatus.ACTIVE ? "In conversation..." : "Idle"}
Â  Â  Â  Â  Â  Â  </p>
Â  Â  Â  Â  Â  </motion.div>
Â  Â  Â  Â  </div>

Â  Â  Â  Â  {/* Message Box */}
Â  Â  Â  Â  {lastMessage && (
Â  Â  Â  Â  Â  <motion.div
Â  Â  Â  Â  Â  Â  className="mt-3 w-[85%] max-w-2xl bg-white/10 backdrop-blur-md border border-white/20 rounded-2xl p-2 shadow-xl text-center"
Â  Â  Â  Â  Â  Â  initial={{ opacity: 0, y: 20 }}
Â  Â  Â  Â  Â  Â  animate={{ opacity: 1, y: 0 }}
Â  Â  Â  Â  Â  Â  transition={{ duration: 0.8 }}
Â  Â  Â  Â  Â  >
Â  Â  Â  Â  Â  Â  <p className="text-white text-sm italic">â€œ{lastMessage}â€</p>
Â  Â  Â  Â  Â  </motion.div>
Â  Â  Â  Â  )}

Â  Â  Â  Â  {/* Control Buttons */}
Â  Â  Â  Â  <div className="flex gap-6 mt-3">
Â  Â  Â  Â  Â  {callStatus !== CallStatus.ACTIVE ? (
Â  Â  Â  Â  Â  Â  <motion.button
Â  Â  Â  Â  Â  Â  Â  onClick={handleCall}
Â  Â  Â  Â  Â  Â  Â  whileHover={{ scale: 1.08 }}
Â  Â  Â  Â  Â  Â  Â  whileTap={{ scale: 0.95 }}
Â  Â  Â  Â  Â  Â  Â  className="relative px-8 py-2 font-bold text-base rounded-full bg-gradient-to-r from-green-500 to-emerald-400 text-white shadow-[0_0_40px_rgba(0,255,150,0.3)] hover:shadow-[0_0_70px_rgba(0,255,150,0.5)] transition-all duration-500"
Â  Â  Â  Â  Â  Â  >
Â  Â  Â  Â  Â  Â  Â  {callStatus === CallStatus.CONNECTING ? "Connecting..." : "Start"}
Â  Â  Â  Â  Â  Â  Â  <span className="absolute inset-0 bg-gradient-to-r from-green-400 to-emerald-500 blur-lg opacity-40 -z-10 animate-pulse"></span>
Â  Â  Â  Â  Â  Â  </motion.button>
Â  Â  Â  Â  Â  ) : (
Â  Â  Â  Â  Â  Â  <motion.button
Â  Â  Â  Â  Â  Â  Â  onClick={handleDisconnect}
Â  Â  Â  Â  Â  Â  Â  whileHover={{ scale: 1.08 }}
Â  Â  Â  Â  Â  Â  Â  whileTap={{ scale: 0.95 }}
Â  Â  Â  Â  Â  Â  Â  className="relative px-8 py-2 font-bold text-base rounded-full bg-gradient-to-r from-red-500 to-pink-500 text-white shadow-[0_0_40px_rgba(255,100,100,0.3)] hover:shadow-[0_0_70px_rgba(255,100,100,0.5)] transition-all duration-500"
Â  Â  Â  Â  Â  Â  >
Â  Â  Â  Â  Â  Â  Â  End
Â  Â  Â  Â  Â  Â  Â  <span className="absolute inset-0 bg-gradient-to-r from-red-500 to-pink-500 blur-lg opacity-40 -z-10 animate-pulse"></span>
Â  Â  Â  Â  Â  Â  </motion.button>
Â  Â  Â  Â  Â  )}
Â  Â  Â  Â  </div>
Â  Â  Â  </div>
Â  Â  </div>
Â  );
};

export default Agent;